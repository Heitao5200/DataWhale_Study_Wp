#Task5 神经网络基础

本次作业目的主要是了解神经网络基础并进行总结。主要关注以下1、2、3、4点。

1. 前馈神经网络、网络层数、输入层、隐藏层、输出层、隐藏单元、激活函数的概念。
2. 感知机相关；利用tensorflow等工具定义简单的几层网络（激活函数sigmoid），递归使用链式法则来实现反向传播。
3. 激活函数的种类以及各自的提出背景、优缺点。（和线性模型对比，线性模型的局限性，去线性化）
4. 深度学习中的正则化（参数范数惩罚：L1正则化、L2正则化；数据集增强；噪声添加；early stop；Dropout层）、正则化的介绍。
5. 深度模型中的优化：参数初始化策略；自适应学习率算法（梯度下降、AdaGrad、RMSProp、Adam；优化算法的选择）；batch norm层（提出背景、解决什么问题、层在训练和测试阶段的计算公式）；layer norm层。

24-宁静致远-Task5 神经网络基础
本次作业目的主要是了解神经网络基础并进行总结。主要关注以下1、2、3、4点。

1. 前馈神经网络概念。https://mp.weixin.qq.com/s?__biz=MzAxMTU5Njg4NQ==&mid=100000867&idx=2&sn=9a89a8cca58dc4226ca710ca2fed4100

2. 感知机相关。https://mp.weixin.qq.com/s?__biz=MzAxMTU5Njg4NQ==&mid=100000867&idx=3&sn=e51617747de265f9f242e602d9fed696

3. 激活函数的种类以及各自的提出背景、优缺点。https://mp.weixin.qq.com/s?__biz=MzAxMTU5Njg4NQ==&mid=100000867&idx=4&sn=762a102bf05f7280156c23efbbb62912

4. 深度学习中的正则化。https://mp.weixin.qq.com/s?__biz=MzAxMTU5Njg4NQ==&mid=100000867&idx=5&sn=25e11ef5f6e014647af1061631047521

5. 深度模型中的优化。https://mp.weixin.qq.com/s?__biz=MzAxMTU5Njg4NQ==&mid=100000867&idx=6&sn=7182dbcb3eaee3c21dbc00c960343c27