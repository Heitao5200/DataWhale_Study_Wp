## Task10 BERT 
 
1. Transformer的原理。
2. BERT的原理。
3. 利用预训练的BERT模型将句子转换为句向量，进行文本分类。 

参考：

transformer github实现：[GitHub - Kyubyong/transformer: A TensorFlow Implem...](https://github.com/Kyubyong/transformer)

transformer pytorch分步实现：[The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

[搞懂Transformer结构，看这篇PyTorch实现就够了：搞懂Transformer结构，看这篇PyTorch实现就够了！ - TinyMind -专注人工智...](https://www.tinymind.cn/articles/3834)

“变形金刚”为何强大：从模型到代码全面解析Google Tensor2Tensor系统：[“变形金刚”为何强大：从模型到代码全面解析Google Tensor2Tensor系统 - 腾讯云技...](https://segmentfault.com/a/1190000015575985)

bert理论：

bert系列1：[https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3](https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3)

bert系列2：[https://medium.com/dissecting-bert/dissecting-bert-part2-335ff2ed9c73](https://medium.com/dissecting-bert/dissecting-bert-part2-335ff2ed9c73)

bert系列3：[https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f](https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f)

5 分钟入门 Google 最强NLP模型：[BERT：5 分钟入门 Google 最强NLP模型：BERT - 简书](https://www.jianshu.com/p/d110d0c13063)

BERT – State of the Art Language Model for NLP：[BERT – State of the Art Language Model for NLP | L...](https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/)

google开源代码：[GitHub - google-research/bert: TensorFlow code and...](https://github.com/google-research/bert)

bert实践：
干货 BERT fine-tune 终极实践教程：[干货 | BERT fine-tune 终极实践教程 - 简书](https://www.jianshu.com/p/aa2eff7ec5c1)

小数据福音！BERT在极小数据下带来显著提升的开源实现：[小数据福音！BERT在极小数据下带来显著提升的开源实现 ](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650752891&idx=5&sn=8a44293a57da96db51b9a13feb6223d7&chksm=871a8305b06d0a134e332a6831dbacc9ee79b28a79658c130fe6162f33211788cab18a55ec90&scene=21#wechat_redirect)

BERT实战（源码分析+踩坑）：[BERT实战（源码分析 踩坑） - 知乎](https://zhuanlan.zhihu.com/p/58471554)